# Environments and simulators for Learning Algorithms
Collection of environments, simulators and competitions for training & benchmarking Reinforcement Learning and AI algorithms.


## Collections of environments
**Gym**. Collection of classic environments for benchmarking RL, such as Atari, MuJoco, etc (OpenAI).
  - Link: https://github.com/openai/gym
  - Gym-compatible
    
**Gym Universe**. Huge collection of various environments for benchmarking RL (OpenAI).
  - Link: https://github.com/openai/universe
  - Gym-compatible

**ALE**. Arcade Learning Environment with Atari games (Marc Bellemare).
  - Link: https://github.com/mgbellemare/Arcade-Learning-Environment
  
**Pycolab**. Customized Grid-World env (DeepMind).
  - Link: https://github.com/deepmind/pycolab

**PettingZoo**. Multi-Agent environment.
  - Link: https://github.com/Farama-Foundation/PettingZoo

## Custom environments
**Unity ML-agents** (Unity Technologies). Allows creating custom AI/RL environments with training support via Unity3D plugin.
  - Link: https://github.com/Unity-Technologies/ml-agents
  - Gym-compatible


## Vehicle Simulation
**Carla** (Intel, Toyota).
  - Link: https://github.com/carla-simulator/carla

**AirSim**. Realistic autonomous vehicle simulator (Microsoft).
  - Link: https://github.com/Microsoft/AirSim


## Navigation
**MineRL**. Minecraft Gym-friendly RL environment along with human player dataset for imitation learning (CMU).
  - Link: https://minerl.io/

**Deepmind Lab**. 3D Navigation in Labyrinths (Deepmind).
  - Link: https://github.com/deepmind/lab

**VizDoom**. 3D Shooting and Navigation Doom game.
  - Link: https://github.com/mwydmuch/ViZDoom
  - Competition (May): http://vizdoom.cs.put.edu.pl/
  
**Project Malmo**. 3D Navigation and Quest Solving in Minecraft game (Microsoft).
  - Link: https://github.com/Microsoft/malmo
  - Competition (April): https://malmo-leaderboard.azurewebsites.net/

**AI2Thor**. Home indoor 3D Navigation.
  - Link: https://github.com/allenai/ai2thor
  - Competition (June): https://competitions.codalab.org/competitions/16929#learn_the_details
    
**HoME Platform**. Home indoor 3D Navigation. Based on SUNCG dataset.
  - Link: https://github.com/HoME-Platform/home-platform
  - Gym-compatible
  
**MINOS**. Home indoor 3D Navigation. Based on SUNCG and Matterport3D datasets (Intel).
  - Link: https://github.com/minosworld/minos
  - Gym-compatible

**House3D**. Home indoor 3D Navigation & Visual Question Answering. Based on SUNCG dataset (Facebook).
  - Link: https://github.com/facebookresearch/House3D
  
**GibsonEnv**. Home indoor 3D Navigation & Locomotion. Based on Gibson, SUNCG, Stanford 2D3DS and Matterport 3D datasets (Stanford).
  - Link: https://github.com/StanfordVL/GibsonEnv
  
**Gym-Maze**. 2D navigation in customizable mazes.
  - Link: https://github.com/zuoxingdong/gym-maze
  - Gym-compatible

## Strategies
**PySC2**. Starcraft II strategy learning environment (Deepmind, Blizzard).
  - Link: https://github.com/deepmind/pysc2
  
**TorchCraft**. Starcraft I strategy learning environment  (Facebook).
  - Link: https://github.com/TorchCraft/TorchCraft/
  - Competitions:
    - SC AI Competition: https://www.cs.mun.ca/~dchurchill/starcraftaicomp/
    - Student SC AI Tournament: https://sscaitournament.com

## Locomotion
**Roboschool**. Locomotion, replicates proprietary MoJoCo environments with additional improvements; OpenAI
  - Link: https://github.com/openai/roboschool
  - Gym-compatible
  
**Control Suite**. Set of locomotion environments based on MuJoCo physics engine (DeepMind).
  - Link: https://github.com/deepmind/dm_control
  - arXiv: https://arxiv.org/abs/1801.00690

## Multi-Agent RL
**PommerMan**. Multi-Agent (up to 4 players) "Bomberman"-like game.
  - Link: https://github.com/MultiAgentLearning/playground
  - Competition: https://www.pommerman.com/competitions

